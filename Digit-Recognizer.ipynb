{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c44f7b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:03.452614Z",
     "iopub.status.busy": "2025-02-04T19:21:03.452178Z",
     "iopub.status.idle": "2025-02-04T19:21:03.464456Z",
     "shell.execute_reply": "2025-02-04T19:21:03.463126Z"
    },
    "papermill": {
     "duration": 0.020139,
     "end_time": "2025-02-04T19:21:03.466938",
     "exception": false,
     "start_time": "2025-02-04T19:21:03.446799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f0dce74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:03.475719Z",
     "iopub.status.busy": "2025-02-04T19:21:03.475328Z",
     "iopub.status.idle": "2025-02-04T19:21:09.857881Z",
     "shell.execute_reply": "2025-02-04T19:21:09.856909Z"
    },
    "papermill": {
     "duration": 6.389686,
     "end_time": "2025-02-04T19:21:09.860334",
     "exception": false,
     "start_time": "2025-02-04T19:21:03.470648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4f1195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:09.868836Z",
     "iopub.status.busy": "2025-02-04T19:21:09.868335Z",
     "iopub.status.idle": "2025-02-04T19:21:14.542403Z",
     "shell.execute_reply": "2025-02-04T19:21:14.541085Z"
    },
    "papermill": {
     "duration": 4.680989,
     "end_time": "2025-02-04T19:21:14.544757",
     "exception": false,
     "start_time": "2025-02-04T19:21:09.863768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
    "\n",
    "train_data.info()\n",
    "\n",
    "train_data.shape[0]\n",
    "#there is one image for each row, so there are 42000 images in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90591e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:14.553819Z",
     "iopub.status.busy": "2025-02-04T19:21:14.553426Z",
     "iopub.status.idle": "2025-02-04T19:21:14.779485Z",
     "shell.execute_reply": "2025-02-04T19:21:14.778237Z"
    },
    "papermill": {
     "duration": 0.233273,
     "end_time": "2025-02-04T19:21:14.781828",
     "exception": false,
     "start_time": "2025-02-04T19:21:14.548555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the first image (excluding the label column)\n",
    "sample_image = train_data.iloc[0, 1:].values  \n",
    "# Take all columns and reshape to 28x28 matrix\n",
    "sample_image = sample_image.reshape(28, 28)  \n",
    "\n",
    "# Plot the image by mapping each pixel value to a corresponding color on a grayscale.\n",
    "# Lower value = darker color.\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.title(f\"The first image drawn is {train_data.iloc[0, 0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3b2fd2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:14.791059Z",
     "iopub.status.busy": "2025-02-04T19:21:14.790672Z",
     "iopub.status.idle": "2025-02-04T19:21:14.795761Z",
     "shell.execute_reply": "2025-02-04T19:21:14.794748Z"
    },
    "papermill": {
     "duration": 0.012054,
     "end_time": "2025-02-04T19:21:14.797723",
     "exception": false,
     "start_time": "2025-02-04T19:21:14.785669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rotation_data_augmentation = 45\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f89d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:14.807298Z",
     "iopub.status.busy": "2025-02-04T19:21:14.806897Z",
     "iopub.status.idle": "2025-02-04T19:21:15.101929Z",
     "shell.execute_reply": "2025-02-04T19:21:15.100455Z"
    },
    "papermill": {
     "duration": 0.30244,
     "end_time": "2025-02-04T19:21:15.104219",
     "exception": false,
     "start_time": "2025-02-04T19:21:14.801779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 33600, Validation samples: 8400\n"
     ]
    }
   ],
   "source": [
    "# Implementing data augmentation\n",
    "\n",
    "# Extract images and labels\n",
    "labels = torch.tensor(train_data.iloc[:, 0].values, dtype=torch.long)  # First column is labels\n",
    "images = train_data.iloc[:, 1:].values.reshape(-1, 1, 28, 28).astype(np.uint8)/255.0  # Reshape images to (N, 1, 28, 28)\n",
    "images = torch.tensor(images, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=rotation_data_augmentation),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n",
    "    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# We don't want to augment the validation set\n",
    "val_transform = transforms.Compose([\n",
    "    #transforms.Normalize((0.5,), (0.5,))  # No augmentation for validation\n",
    "])\n",
    "\n",
    "class AugmentedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformation\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "# Create dataset with augmentation\n",
    "# train_dataset = AugmentedDataset(images, labels, transform=train_transform)\n",
    "# From the 42000 training examples we create batches of size 64. After each epoch (once we train the model once through all examples)\n",
    "# The new epoch will see randomly rotation images from the train dataset. \n",
    "#train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "full_dataset = AugmentedDataset(images, labels, transform=train_transform)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d7c3c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:15.114800Z",
     "iopub.status.busy": "2025-02-04T19:21:15.113761Z",
     "iopub.status.idle": "2025-02-04T19:21:15.123393Z",
     "shell.execute_reply": "2025-02-04T19:21:15.122284Z"
    },
    "papermill": {
     "duration": 0.017107,
     "end_time": "2025-02-04T19:21:15.125443",
     "exception": false,
     "start_time": "2025-02-04T19:21:15.108336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We now create a class which inherits the properties of nn.Module.\n",
    "# This class will define the layers and operations the model will use.\n",
    "\n",
    "class DigitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128*3*3, 128)  \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        #self.dropout2 = nn.Dropout(0.3)\n",
    "        #self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        #x = self.global_avg_pool(x)  \n",
    "        #x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0bcdf5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:15.134899Z",
     "iopub.status.busy": "2025-02-04T19:21:15.134504Z",
     "iopub.status.idle": "2025-02-04T19:21:15.183373Z",
     "shell.execute_reply": "2025-02-04T19:21:15.182285Z"
    },
    "papermill": {
     "duration": 0.056388,
     "end_time": "2025-02-04T19:21:15.185832",
     "exception": false,
     "start_time": "2025-02-04T19:21:15.129444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DigitModel().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout & batch norm updates)\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradient calculation for validation (faster & saves memory)\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move to GPU if available\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)  # Compute average loss\n",
    "    val_acc = 100 * correct / total  # Compute accuracy\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75f5651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:21:15.196098Z",
     "iopub.status.busy": "2025-02-04T19:21:15.195280Z",
     "iopub.status.idle": "2025-02-04T19:28:43.812134Z",
     "shell.execute_reply": "2025-02-04T19:28:43.810787Z"
    },
    "papermill": {
     "duration": 448.628246,
     "end_time": "2025-02-04T19:28:43.818173",
     "exception": false,
     "start_time": "2025-02-04T19:21:15.189927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 0.2496, Train Acc: 92.48% | Val Loss: 0.0535, Val Acc: 98.21%\n",
      "Epoch [2/10] - Train Loss: 0.0875, Train Acc: 97.49% | Val Loss: 0.0633, Val Acc: 98.05%\n",
      "Epoch [3/10] - Train Loss: 0.0545, Train Acc: 98.49% | Val Loss: 0.0306, Val Acc: 99.11%\n",
      "Epoch [4/10] - Train Loss: 0.0520, Train Acc: 98.56% | Val Loss: 0.0358, Val Acc: 98.92%\n",
      "Epoch [5/10] - Train Loss: 0.0338, Train Acc: 99.07% | Val Loss: 0.0324, Val Acc: 98.96%\n",
      "Epoch [6/10] - Train Loss: 0.0292, Train Acc: 99.26% | Val Loss: 0.0230, Val Acc: 99.21%\n",
      "Epoch [7/10] - Train Loss: 0.0246, Train Acc: 99.35% | Val Loss: 0.0250, Val Acc: 99.19%\n",
      "Epoch [8/10] - Train Loss: 0.0218, Train Acc: 99.42% | Val Loss: 0.0244, Val Acc: 99.25%\n",
      "Epoch [9/10] - Train Loss: 0.0182, Train Acc: 99.60% | Val Loss: 0.0225, Val Acc: 99.27%\n",
      "Epoch [10/10] - Train Loss: 0.0154, Train Acc: 99.66% | Val Loss: 0.0230, Val Acc: 99.33%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move batch to GPU\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea0e498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T19:28:43.828646Z",
     "iopub.status.busy": "2025-02-04T19:28:43.828260Z",
     "iopub.status.idle": "2025-02-04T19:29:01.932594Z",
     "shell.execute_reply": "2025-02-04T19:29:01.931415Z"
    },
    "papermill": {
     "duration": 18.112313,
     "end_time": "2025-02-04T19:29:01.934878",
     "exception": false,
     "start_time": "2025-02-04T19:28:43.822565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as submission.csv\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
    "test_images = torch.tensor(test_data.values.reshape(-1, 1, 28, 28), dtype=torch.float32)/255.0\n",
    "test_loader = DataLoader(test_images, batch_size=64, shuffle=False)\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  # No gradients needed during inference\n",
    "    for images in test_loader:\n",
    "        outputs = model(images)  # Forward pass\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "        predictions.extend(predicted.cpu().numpy())  # Store predictions\n",
    "\n",
    "submission = pd.DataFrame({'ImageId': np.arange(1, len(predictions) + 1), 'Label': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894190a",
   "metadata": {
    "papermill": {
     "duration": 0.004372,
     "end_time": "2025-02-04T19:29:01.943830",
     "exception": false,
     "start_time": "2025-02-04T19:29:01.939458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 483.260835,
   "end_time": "2025-02-04T19:29:03.071973",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-04T19:20:59.811138",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
